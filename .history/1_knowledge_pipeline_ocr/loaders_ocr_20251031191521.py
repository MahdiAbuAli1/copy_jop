# 1_knowledge_pipeline_ocr/loaders_ocr.py

import os
import json
from typing import List, Tuple, Optional
import fitz  # PyMuPDF
from PIL import Image
import pytesseract
import io
import numpy as np
import cv2  # OpenCV for image pre-processing

from langchain_core.documents import Document
from langchain_community.document_loaders import (
    UnstructuredWordDocumentLoader,
    TextLoader,
)

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª OCR ---
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† tesseract-ocr-ara Ù…Ø«Ø¨Øª Ù„Ø¯ÙŠÙƒ
TESSERACT_LANG = 'ara+eng'
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Tesseract Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©
# psm 6: ÙŠÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ ÙƒØªÙ„Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ­Ø¯.
# dpi 300: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¯Ù‚Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¹Ø±Ù.
TESSERACT_CONFIG = '--psm 6 --dpi 300'

def preprocess_image_for_ocr(image_bytes: bytes) -> Image.Image:
    """
    ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ø¥Ù„Ù‰ OCR Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©.
    """
    # 1. ØªØ­ÙˆÙŠÙ„ Ø¨Ø§ÙŠØªØ§Øª Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© OpenCV
    nparr = np.frombuffer(image_bytes, np.uint8)
    img_cv = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ
    gray_img = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    
    # 3. ØªØ·Ø¨ÙŠÙ‚ Adaptive Thresholding Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø­Ø±ÙˆÙ Ø¨Ø§Ø±Ø²Ø© (Ø£Ø¨ÙŠØ¶ ÙˆØ£Ø³ÙˆØ¯)
    # Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø£ÙØ¶Ù„ Ù…Ù† Ø§Ù„Ù€ thresholding Ø§Ù„Ø¨Ø³ÙŠØ· Ù„Ù„ØµÙˆØ± Ø°Ø§Øª Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø©.
    processed_img = cv2.adaptiveThreshold(
        gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY, 11, 2
    )
    
    # 4. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† PIL Image
    return Image.fromarray(processed_img)


# --- Ù…Ø­Ù…Ù„ PDF Ø§Ù„Ù…Ø®ØµØµ ÙˆØ§Ù„Ù…ÙØ­Ø³ÙÙ‘Ù† Ù…Ø¹ Ø¯Ø¹Ù… OCR ---
class AdvancedPDFLoader:
    def __init__(self, file_path: str):
        self.file_path = file_path

    def load(self) -> List[Document]:
        """
        ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù PDFØŒ ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© ÙˆØ§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ± (OCR) Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©ØŒ
        Ù…Ø¹ ÙØµÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù…Ù†Ø¹ Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙƒØ±Ø§Ø±.
        """
        docs = []
        try:
            pdf_document = fitz.open(self.file_path)
            print(f"    - ğŸ“– Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© {len(pdf_document)} ØµÙØ­Ø© Ù…Ù† '{os.path.basename(self.file_path)}'...")
            
            for page_num, page in enumerate(pdf_document):
                # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ù…Ù† Ø§Ù„ØµÙØ­Ø©
                normal_text = page.get_text("text").strip()
                
                # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø©
                ocr_texts = []
                image_list = page.get_images(full=True)
                
                if image_list:
                    print(f"      - ğŸ–¼ï¸ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(image_list)} ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num + 1}. Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„Ù‡Ø§ Ø¨Ø¯Ù‚Ø©...")
                    for img_index, img in enumerate(image_list):
                        xref = img[0]
                        base_image = pdf_document.extract_image(xref)
                        image_bytes = base_image["image"]
                        
                        try:
                            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ù€ OCR
                            preprocessed_image = preprocess_image_for_ocr(image_bytes)
                            
                            # Ø§Ø³ØªØ®Ø¯Ø§Ù… tesseract Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙØ­Ø³ÙÙ‘Ù†Ø©
                            additional_text = pytesseract.image_to_string(
                                preprocessed_image, 
                                lang=TESSERACT_LANG,
                                config=TESSERACT_CONFIG
                            )
                            
                            if additional_text.strip():
                                ocr_texts.append(additional_text.strip())
                        except Exception as ocr_e:
                            print(f"        - âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num + 1}. Ø§Ù„Ø®Ø·Ø£: {ocr_e}")

                # 3. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„ØµÙØ­Ø© (Ø¨Ø¯ÙˆÙ† Ø¯Ù…Ø¬ Ø¹Ø´ÙˆØ§Ø¦ÙŠ)
                page_content_parts = []
                if normal_text:
                    page_content_parts.append("--- Ù…Ø­ØªÙˆÙ‰ Ù†ØµÙŠ ---\n" + normal_text)
                
                if ocr_texts:
                    # Ø¯Ù…Ø¬ ÙƒÙ„ Ù†ØµÙˆØµ OCR Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† ØµÙˆØ± Ø§Ù„ØµÙØ­Ø©
                    full_ocr_text = "\n\n".join(ocr_texts)
                    page_content_parts.append("--- Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„ØµÙˆØ± (OCR) ---\n" + full_ocr_text)
                
                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„ØµÙØ­Ø©
                final_page_content = "\n\n".join(page_content_parts)
                
                # Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Document Ù„Ù„ØµÙØ­Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø­ØªÙˆÙ‰
                if final_page_content:
                    metadata = {
                        "source": self.file_path,
                        "page": page_num + 1,
                    }
                    doc = Document(page_content=final_page_content, metadata=metadata)
                    docs.append(doc)
                
            pdf_document.close()
        except Exception as e:
            print(f"    - âŒ ÙØ´Ù„ ÙƒØ¨ÙŠØ± ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© PDF '{self.file_path}'. Ø§Ù„Ø®Ø·Ø£: {e}")
            return []
            
        return docs

# --- ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ---
LOADER_MAPPING = {
    ".pdf": AdvancedPDFLoader,  # <-- âœ¨âœ¨ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£Ù‚ÙˆÙ‰ Ù‡Ù†Ø§ âœ¨âœ¨
    ".docx": UnstructuredWordDocumentLoader,
    ".txt": TextLoader,
}

# --- Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ) ---
def load_documents(source_dir: str) -> Tuple[List[Document], Optional[str]]:
    """
    ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ù…Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø§Ù„Ø°ÙŠ ÙŠØ¯Ø¹Ù… OCR.
    """
    all_documents = []
    entity_name = None
    config_file_path = os.path.join(source_dir, "config.json")

    print(f"ğŸ“‚ Ø¬Ø§Ø±Ù Ø§Ù„Ù…Ø³Ø­ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: '{source_dir}'")

    if not os.path.isdir(source_dir):
        raise ValueError(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„ÙŠØ³ Ù…Ø¬Ù„Ø¯Ù‹Ø§ ØµØ§Ù„Ø­Ù‹Ø§: {source_dir}")

    if os.path.exists(config_file_path):
        try:
            with open(config_file_path, "r", encoding="utf-8") as f:
                config_data = json.load(f)
                entity_name = config_data.get("entity_name")
                if entity_name:
                    print(f"  - âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ÙƒÙŠØ§Ù†: '{entity_name}'")
                else:
                    print(f"  - âš ï¸ ØªØ­Ø°ÙŠØ±: Ù…Ù„Ù 'config.json' Ù…ÙˆØ¬ÙˆØ¯ ÙˆÙ„ÙƒÙ†Ù‡ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'entity_name'.")
        except Exception as e:
            print(f"  - âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© 'config.json': {e}")
    else:
        print(f"  - âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù 'config.json'. Ù„Ù† ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù‡ÙˆÙŠØ© Ù„Ù„Ø¹Ù…ÙŠÙ„.")

    for filename in os.listdir(source_dir):
        if filename == "config.json":
            continue
        
        file_path = os.path.join(source_dir, filename)
        if not os.path.isfile(file_path) or filename.startswith('.'):
            continue

        file_ext = os.path.splitext(filename)[1].lower()
        if file_ext in LOADER_MAPPING:
            loader_class = LOADER_MAPPING[file_ext]
            print(f"  - ğŸ“„ Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: '{filename}'...")
            try:
                loader = loader_class(file_path)
                loaded_docs = loader.load()
                all_documents.extend(loaded_docs)
                print(f"    - âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© {len(loaded_docs)} ØµÙØ­Ø©.")
            except Exception as e:
                print(f"    - âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù '{filename}'. Ø§Ù„Ø®Ø·Ø£: {e}")
        else:
            print(f"  -  ØªÙ… ØªØ®Ø·ÙŠ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: '{filename}'")

    if not all_documents:
        print(" Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
    
    print(f"\n Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„. Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(all_documents)}")
    return all_documents, entity_name

