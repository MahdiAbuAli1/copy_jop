# 2_evaluation_suite/run_evaluation.py (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ÙˆØ§Ù„Ø´Ø§Ù…Ù„Ø©)

import os
import json
import argparse
import time
from datetime import datetime
from typing import List, Dict, Any, Literal
from dotenv import load_dotenv

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
from core.retriever_factory import get_retriever
from core.evaluators import evaluate_retrieval
from core.reranker import rerank_documents # <-- Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ­Ø¯Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ---
load_dotenv()
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEST_CASES_DIR = os.path.join(BASE_DIR, "test_cases")
RESULTS_DIR = os.path.join(BASE_DIR, "results")

# --- ØªØ¹Ø±ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© ---
RetrieverType = Literal["hybrid", "ensemble", "faiss", "bm25"]

def load_all_documents_from_kb() -> List[Any]:
    from langchain_community.vectorstores import FAISS
    from langchain_community.embeddings import OllamaEmbeddings
    
    db_path = os.path.abspath(os.path.join(BASE_DIR, "../3_shared_resources/vector_db/"))
    if not os.path.exists(os.path.join(db_path, "index.faiss")):
        raise FileNotFoundError("Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª FAISS ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©!")
        
    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)
    db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    
    return list(db.docstore._dict.values())

def run_test_for_tenant(
    tenant_id: str,
    retriever_type: RetrieverType,
    all_docs: List[Any]
) -> List[Dict[str, Any]]:
    print("\n" + "="*30 + f" ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¹Ù…ÙŠÙ„: {tenant_id} | Ø§Ù„Ù†ÙˆØ¹: {retriever_type} " + "="*30)
    
    test_cases_file = os.path.join(TEST_CASES_DIR, f"{tenant_id}_cases.json")
    if not os.path.exists(test_cases_file):
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø­Ø§Ù„Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„Ø¹Ù…ÙŠÙ„ '{tenant_id}'. ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ.")
        return []
    
    with open(test_cases_file, 'r', encoding='utf-8') as f:
        test_cases = json.load(f)
    print(f"  - ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(test_cases)} Ø­Ø§Ù„Ø© Ø§Ø®ØªØ¨Ø§Ø±.")

    tenant_specific_docs = [doc for doc in all_docs if doc.metadata.get("tenant_id") == tenant_id]
    if not tenant_specific_docs:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù„Ø¹Ù…ÙŠÙ„ '{tenant_id}'. ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ.")
        return []

    # --- 1. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹ ---
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†ÙˆØ¹ 'hybrid'ØŒ ÙØ³Ù†Ø³ØªØ®Ø¯Ù… 'ensemble' Ù„Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø£ÙˆÙ„ÙŠ
    base_retriever_type = "ensemble" if retriever_type == "hybrid" else retriever_type
    # Ù†Ø·Ù„Ø¨ Ø¹Ø¯Ø¯Ø§Ù‹ Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ù€ hybrid Ù„Ù†Ø¹Ø·ÙŠ ÙØ±ØµØ© Ù„Ù„Ù€ reranker
    k_value = 20 if retriever_type == "hybrid" else 5
    
    retriever = get_retriever(base_retriever_type, tenant_specific_docs, EMBEDDING_MODEL_NAME, k=k_value)

    results = []
    for case in test_cases:
        question = case["question"]
        print(f"\n--- â“ Ø§Ø®ØªØ¨Ø§Ø± [{case['case_id']}]: {question} ---")
        
        # --- 2. Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ ---
        start_time = time.time()
        retrieved_docs_langchain = retriever.invoke(question)
        retrieval_time = time.time() - start_time
        
        retrieved_docs_simple = [
            {
                "content": doc.page_content,
                "source": doc.metadata.get("source", "N/A"),
                "chunk_id": doc.metadata.get("chunk_id", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯") # Ù…Ø«Ø§Ù„ Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø±Ù Ø§Ù„Ù‚Ø·Ø¹Ø©
            }
            for doc in retrieved_docs_langchain
        ]

        # --- 3. Ù…Ø±Ø­Ù„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ (ÙÙ‚Ø· Ù„Ù„Ù†ÙˆØ¹ Ø§Ù„Ù‡Ø¬ÙŠÙ†) ---
        final_docs = retrieved_docs_simple
        rerank_time = 0
        if retriever_type == "hybrid":
            print(f"  - ğŸ”ƒ Ø¬Ø§Ø±Ù Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ {len(retrieved_docs_simple)} Ù…Ø³ØªÙ†Ø¯...")
            rerank_start_time = time.time()
            final_docs = rerank_documents(question, retrieved_docs_simple)
            rerank_time = time.time() - rerank_start_time
            print(f"  - âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ ÙÙŠ {rerank_time:.2f} Ø«Ø§Ù†ÙŠØ©.")
            # Ù†Ø£Ø®Ø° Ø£ÙØ¶Ù„ 5 Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¹Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨
            final_docs = final_docs[:5]

        # --- 4. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ø­ÙØ¸ ---
        evaluation = evaluate_retrieval(
            retrieved_docs=final_docs, # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„ØªÙ‚ÙŠÙŠÙ…
            expected_keywords=case["expected_keywords"],
            expected_source=case["expected_source"]
        )
        
        print(f"  - ğŸ“Š Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {evaluation['status']} (Ø§Ù„Ù…ØµØ¯Ø±: {evaluation['source_check']}, Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {evaluation['keyword_evaluation']['score']})")
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ø´Ø§Ù…Ù„Ø© Ù„Ù„ØªÙ‚Ø±ÙŠØ±
        detailed_docs = []
        for i, doc in enumerate(final_docs):
            detailed_docs.append({
                "final_rank": i + 1,
                "content": doc["content"],
                "source": doc["source"],
                "original_rank": doc.get("original_rank", "N/A"), # Ù…Ù† Ø§Ù„Ù€ reranker
                "rerank_score": f"{doc.get('rerank_score', 'N/A'):.4f}" if isinstance(doc.get('rerank_score'), float) else "N/A"
            })

        results.append({
            "case_id": case["case_id"],
            "question": question,
            "timing": {
                "retrieval_seconds": round(retrieval_time, 2),
                "rerank_seconds": round(rerank_time, 2),
                "total_seconds": round(retrieval_time + rerank_time, 2)
            },
            "evaluation": evaluation,
            "retrieved_documents": detailed_docs
        })
        
    return results

def save_results(tenant_id: str, retriever_type: RetrieverType, results: List[Dict[str, Any]]):
    if not results: return
    os.makedirs(RESULTS_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_{tenant_id}_{retriever_type}.json"
    filepath = os.path.join(RESULTS_DIR, filename)
    
    report = {
        "report_info": {
            "tenant_id": tenant_id,
            "retriever_type": retriever_type,
            "timestamp": datetime.now().isoformat(),
            "embedding_model": EMBEDDING_MODEL_NAME,
            "total_cases": len(results)
        },
        "evaluation_results": results
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=4)
        
    print("\n" + f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙØµÙ„ ÙÙŠ: {filepath}")

def main():
    parser = argparse.ArgumentParser(description="Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹.")
    parser.add_argument("--tenant", type=str, required=True, help="Ù‡ÙˆÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„. Ø§ÙƒØªØ¨ 'all' Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡.")
    parser.add_argument(
        "--retriever", 
        type=str, 
        default="all", 
        choices=["all", "hybrid", "ensemble", "faiss", "bm25"],
        help="Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹."
    )
    args = parser.parse_args()

    print("[*] Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ†...")
    try:
        all_docs_from_kb = load_all_documents_from_kb()
        print(f"[âœ…] ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(all_docs_from_kb)} Ù‚Ø·Ø¹Ø© Ø¨Ù†Ø¬Ø§Ø­.")
    except Exception as e:
        print(f"[âŒ] ÙØ´Ù„ Ø­Ø§Ø³Ù… ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")
        return

    tenants_to_test = [d.replace('_cases.json', '') for d in os.listdir(TEST_CASES_DIR) if d.endswith('_cases.json')]
    if args.tenant != "all":
        if args.tenant not in tenants_to_test:
            print(f"Ø®Ø·Ø£: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø­Ø§Ù„Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„Ø¹Ù…ÙŠÙ„ '{args.tenant}'.")
            return
        tenants_to_test = [args.tenant]

    retrievers_to_test = ["hybrid", "ensemble", "faiss", "bm25"] if args.retriever == "all" else [args.retriever]

    for tenant in tenants_to_test:
        for retriever_name in retrievers_to_test:
            test_results = run_test_for_tenant(tenant, retriever_name, all_docs_from_kb)
            save_results(tenant, retriever_name, test_results)
            
    print("\n" + "="*70 + "\nğŸ‰ğŸ‰ğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ø¬Ù…ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰ğŸ‰ğŸ‰\n" + "="*70)
    print(f"ğŸ” ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ÙØµÙ„Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯: {RESULTS_DIR}")

if __name__ == "__main__":
    main()
