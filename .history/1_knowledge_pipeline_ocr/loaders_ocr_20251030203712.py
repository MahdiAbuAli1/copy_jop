# 1_knowledge_pipeline_ocr/loaders_ocr.py

import os
import json
from typing import List, Tuple, Optional
import fitz  # PyMuPDF
from PIL import Image
import pytesseract
import io

from langchain_core.documents import Document
from langchain_community.document_loaders import (
    UnstructuredWordDocumentLoader,
    TextLoader,
)

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª OCR ---
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† tesseract-ocr-ara Ù…Ø«Ø¨Øª Ù„Ø¯ÙŠÙƒ
TESSERACT_LANG = 'ara+eng' 

# --- Ù…Ø­Ù…Ù„ PDF Ø§Ù„Ù…Ø®ØµØµ Ù…Ø¹ Ø¯Ø¹Ù… OCR ---
class AdvancedPDFLoader:
    def __init__(self, file_path: str):
        self.file_path = file_path

    def load(self) -> List[Document]:
        """
        ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù PDFØŒ ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© ÙˆØ§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ± (OCR).
        """
        docs = []
        try:
            pdf_document = fitz.open(self.file_path)
            print(f"    - ğŸ“– Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© {len(pdf_document)} ØµÙØ­Ø© Ù…Ù† '{os.path.basename(self.file_path)}'...")
            
            for page_num, page in enumerate(pdf_document):
                # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                text = page.get_text("text")
                
                # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR
                ocr_text = ""
                image_list = page.get_images(full=True)
                if image_list:
                    print(f"      - ğŸ–¼ï¸ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(image_list)} ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num + 1}. Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„Ù‡Ø§...")
                    for img_index, img in enumerate(image_list):
                        xref = img[0]
                        base_image = pdf_document.extract_image(xref)
                        image_bytes = base_image["image"]
                        
                        try:
                            image = Image.open(io.BytesIO(image_bytes))
                            # Ø§Ø³ØªØ®Ø¯Ø§Ù… tesseract Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
                            additional_text = pytesseract.image_to_string(image, lang=TESSERACT_LANG)
                            if additional_text.strip():
                                ocr_text += f"\n--- OCR Text from Image {img_index + 1} ---\n{additional_text.strip()}"
                        except Exception as ocr_e:
                            print(f"        - âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num + 1}. Ø§Ù„Ø®Ø·Ø£: {ocr_e}")

                # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ
                combined_text = text + ocr_text
                
                # Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Document Ù„Ù„ØµÙØ­Ø©
                metadata = {
                    "source": self.file_path,
                    "page": page_num + 1,
                }
                doc = Document(page_content=combined_text, metadata=metadata)
                docs.append(doc)
                
            pdf_document.close()
        except Exception as e:
            print(f"    - âŒ ÙØ´Ù„ ÙƒØ¨ÙŠØ± ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© PDF '{self.file_path}'. Ø§Ù„Ø®Ø·Ø£: {e}")
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ØŒ Ù†Ø±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù
            return []
            
        return docs

# --- ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ---
LOADER_MAPPING = {
    ".pdf": AdvancedPDFLoader,  # <-- âœ¨âœ¨ Ø§Ù„ØªØ±Ù‚ÙŠØ© Ù‡Ù†Ø§ âœ¨âœ¨
    ".docx": UnstructuredWordDocumentLoader,
    ".txt": TextLoader,
}

# --- Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹) ---
def load_documents(source_dir: str) -> Tuple[List[Document], Optional[str]]:
    """
    ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ù…Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø§Ù„Ø°ÙŠ ÙŠØ¯Ø¹Ù… OCR.
    """
    # ... (Ø¨Ù‚ÙŠØ© Ø§Ù„ÙƒÙˆØ¯ Ù…Ù† Ù…Ù„Ù loaders.py Ø§Ù„Ø£ØµÙ„ÙŠ ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ ØªÙ…Ø§Ù…Ø§Ù‹) ...
    all_documents = []
    entity_name = None
    config_file_path = os.path.join(source_dir, "config.json")

    print(f"ğŸ“‚ Ø¬Ø§Ø±Ù Ø§Ù„Ù…Ø³Ø­ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±: '{source_dir}'")

    if not os.path.isdir(source_dir):
        raise ValueError(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„ÙŠØ³ Ù…Ø¬Ù„Ø¯Ù‹Ø§ ØµØ§Ù„Ø­Ù‹Ø§: {source_dir}")

    if os.path.exists(config_file_path):
        try:
            with open(config_file_path, "r", encoding="utf-8") as f:
                config_data = json.load(f)
                entity_name = config_data.get("entity_name")
                if entity_name:
                    print(f"  - âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ÙƒÙŠØ§Ù†: '{entity_name}'")
                else:
                    print(f"  - âš ï¸ ØªØ­Ø°ÙŠØ±: Ù…Ù„Ù 'config.json' Ù…ÙˆØ¬ÙˆØ¯ ÙˆÙ„ÙƒÙ†Ù‡ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'entity_name'.")
        except Exception as e:
            print(f"  - âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© 'config.json': {e}")
    else:
        print(f"  - âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù 'config.json'. Ù„Ù† ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù‡ÙˆÙŠØ© Ù„Ù„Ø¹Ù…ÙŠÙ„.")

    for filename in os.listdir(source_dir):
        if filename == "config.json":
            continue
        
        file_path = os.path.join(source_dir, filename)
        if not os.path.isfile(file_path) or filename.startswith('.'):
            continue

        file_ext = os.path.splitext(filename)[1].lower()
        if file_ext in LOADER_MAPPING:
            loader_class = LOADER_MAPPING[file_ext]
            print(f"  - ğŸ“„ Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: '{filename}'...")
            try:
                # Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ù„ØªÙ…Ø±ÙŠØ± encoding Ù„Ù„Ù…Ø­Ù…Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                loader = loader_class(file_path)
                loaded_docs = loader.load()
                all_documents.extend(loaded_docs)
                print(f"    - âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© {len(loaded_docs)} ØµÙØ­Ø©.")
            except Exception as e:
                print(f"    - âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù '{filename}'. Ø§Ù„Ø®Ø·Ø£: {e}")
        else:
            print(f"  -  ØªÙ… ØªØ®Ø·ÙŠ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: '{filename}'")

    if not all_documents:
        print(" Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
    
    print(f"\n Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„. Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(all_documents)}")
    return all_documents, entity_name
