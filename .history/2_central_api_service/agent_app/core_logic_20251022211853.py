# core_logic.py (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© - Ù…Ø¹ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ ÙˆØ§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© )

import os
import logging
import time
from typing import List, AsyncGenerator, Dict
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama
from dotenv import load_dotenv
import langchain
from langchain_core.caches import InMemoryCache
from langchain_core.documents import Document
from sentence_transformers import CrossEncoder
from rank_bm25 import BM25Okapi

from .performance_tracker import PerformanceLogger

# -----------------------------------------------------------------------------
# ğŸ§© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© ÙˆØªØ³Ø¬ÙŠÙ„
# -----------------------------------------------------------------------------
perf_logger = PerformanceLogger()
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
load_dotenv(dotenv_path=os.path.abspath(os.path.join(os.path.dirname(__file__), "../../.env")))
langchain.llm_cache = InMemoryCache()

# -----------------------------------------------------------------------------
# ğŸ“¦ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬
# -----------------------------------------------------------------------------
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")
CHAT_MODEL_NAME = os.getenv("CHAT_MODEL_NAME")
VECTOR_DB_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../3_shared_resources/vector_db"))
RERANK_MODEL_NAME = "BAAI/bge-reranker-base"
# --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: Ù‚Ø±Ø§Ø¡Ø© Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ø¯Ù… Ollama Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ---
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434" )

# -----------------------------------------------------------------------------
# ğŸ§  Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ù€ Prompts (Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©)
# -----------------------------------------------------------------------------

# --- 1. Ù‚Ø§Ù„Ø¨ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ (Classifier) ---
ROUTING_PROMPT_TEMPLATE = """
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªØµÙ†ÙŠÙ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ø£Ø­Ø¯ Ø§Ù„ÙØ¦ØªÙŠÙ† Ø§Ù„ØªØ§Ù„ÙŠØªÙŠÙ†: "technical" Ø£Ùˆ "general".
- "technical": Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØªØ·Ù„Ø¨ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ùˆ ØªÙØ§ØµÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ©. (Ù…Ø«Ù„: Ù…Ù† Ù‡Ùˆ Ø§Ù„Ù…Ø´Ø±ÙØŒ Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØŒ ÙƒÙŠÙ Ø£Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©).
- "general": Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ØªØ­ÙŠØ©ØŒ Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù… Ù„Ø§ ÙŠØªØ·Ù„Ø¨ Ø¨Ø­Ø« (Ù…Ø«Ù„ "Ù…Ù† Ø£Ù†ØªØŸ"ØŒ "ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ")ØŒ Ø­Ø¯ÙŠØ« ØµØºÙŠØ±ØŒ Ø£Ùˆ Ø¥Ù‡Ø§Ù†Ø©.

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·ØŒ Ù…Ø¹ Ù…ÙØªØ§Ø­ "category".

Ø£Ù…Ø«Ù„Ø©:
- Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ø®Ø·ÙˆØ§Øª ØªØ«Ø¨ÙŠØª Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬." -> {{"category": "technical"}}
- Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ù…Ù† Ù‡Ùˆ Ù…Ù‡Ø¯ÙŠ Ø£Ø¨Ùˆ Ø¹Ù„ÙŠØŸ" -> {{"category": "technical"}}
- Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ù…Ø±Ø­Ø¨Ø§Ù‹ ÙŠØ§ Ø³Ø§Ø¹Ø¯" -> {{"category": "general"}}
- Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ù…Ù† ØªÙƒÙˆÙ†ØŸ" -> {{"category": "general"}}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{question}
"""

# --- 2. Ù‚Ø§Ù„Ø¨ Ù†Ø¸Ø§Ù… RAG Ø§Ù„ØªÙ‚Ù†ÙŠ ---
RAG_PROMPT_TEMPLATE = """
**Ù…Ù‡Ù…ØªÙƒ:** Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¯Ø¹Ù… ÙÙ†ÙŠ Ø®Ø¨ÙŠØ± ÙˆÙ…Ø®ØªØµ Ù„Ù€ **{tenant_name}**. Ø§Ø³ØªØ®Ø¯Ù… "Ø§Ù„Ø³ÙŠØ§Ù‚" Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ "Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…" Ø¨Ø¯Ù‚Ø©.
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ø£Ø¬Ø¨ Ø¨Ù€ "Ø£Ù†Ø§ Ø¢Ø³ÙØŒ Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."
- Ø£Ø¬Ø¨ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

**Ø§Ù„Ø³ÙŠØ§Ù‚:**
{context}

**Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:**
{question}

**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
"""

# --- 3. Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (Ù…Ø¹ Ø´Ø®ØµÙŠØ© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©) ---
GENERAL_PROMPT_TEMPLATE = """
**Ù…Ù‡Ù…ØªÙƒ:** Ø£Ù†Øª "Ø³Ø§Ø¹Ø¯"ØŒ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù€ **{tenant_name}**. Ø£Ù†Øª Ø°ÙƒÙŠ ÙˆÙˆØ¯ÙˆØ¯. ØªÙØ§Ø¹Ù„ Ù…Ø¹ "Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…" Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø§Ø³Ø¨Ø© ÙˆÙ…Ù‡Ø°Ø¨Ø©.
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ "Ù…Ù† Ø£Ù†ØªØŸ" Ø£Ùˆ Ù…Ø§ Ø´Ø§Ø¨Ù‡: Ø¹Ø±Ù‘Ù Ø¨Ù†ÙØ³Ùƒ: "Ø£Ù†Ø§ Ø³Ø§Ø¹Ø¯ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù€ {tenant_name}. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒØŸ"
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ØªØ­ÙŠØ©: Ø±Ø¯ Ø§Ù„ØªØ­ÙŠØ© Ø¨Ù„Ø·Ù. (Ù…Ø«Ø§Ù„: "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…! Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯Ø¹Ù… Ù„Ù€ {tenant_name}.")
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù‡Ø§Ù†Ø©: Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù‡Ø¯ÙˆØ¦Ùƒ ÙˆØ±Ø¯ Ø¨Ø§Ø­ØªØ±Ø§ÙÙŠØ©: "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ù„Ø¯ÙŠÙƒ Ø­ÙˆÙ„ {tenant_name}."
- Ø£Ø¬Ø¨ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{question}
"""

# -----------------------------------------------------------------------------
# ğŸŒ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© ÙˆØ³Ù„Ø§Ø³Ù„ Ø§Ù„Ø¹Ù…Ù„
# -----------------------------------------------------------------------------
vector_store: FAISS = None
llm: Ollama = None
embeddings_model: OllamaEmbeddings = None
all_docs_for_bm25: List[Document] = []
cross_encoder: CrossEncoder = None
full_rag_chain = None
general_chain = None
routing_chain = None

# -----------------------------------------------------------------------------
# ğŸš€ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ (Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡)
# -----------------------------------------------------------------------------
def initialize_agent():
    global vector_store, llm, embeddings_model, all_docs_for_bm25, cross_encoder, full_rag_chain, general_chain, routing_chain
    if routing_chain:
        logging.info("âœ… Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ (Ù…Ø¹ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡) Ù…ÙÙ‡ÙŠØ£ Ù…Ø³Ø¨Ù‚Ù‹Ø§.")
        return
    
    try:
        logging.info("=" * 80)
        logging.info("ğŸš€ Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ (Ù…Ø¹ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ ÙˆØ§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©)...")
        logging.info(f"ğŸ”— Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø§Ø¯Ù… Ollama Ø¹Ù„Ù‰: {OLLAMA_HOST}")
        
        # --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: Ø¥Ø¶Ø§ÙØ© base_url Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Docker ---
        llm = Ollama(model=CHAT_MODEL_NAME, temperature=0.1, base_url=OLLAMA_HOST)
        embeddings_model = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME, base_url=OLLAMA_HOST)
        
        vector_store = FAISS.load_local(VECTOR_DB_PATH, embeddings=embeddings_model, allow_dangerous_deserialization=True)
        docstore_ids = list(vector_store.docstore._dict.keys())
        all_docs_for_bm25 = [vector_store.docstore._dict[i] for i in docstore_ids]
        # cross_encoder = CrossEncoder(RERANK_MODEL_NAME)
        
        # --- Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ ---
        rag_prompt = PromptTemplate.from_template(RAG_PROMPT_TEMPLATE)
        full_rag_chain = (
            RunnablePassthrough.assign(context=lambda x: format_docs_with_source(x["docs"]))
            | rag_prompt
            | llm
            | StrOutputParser()
        )

        general_prompt = PromptTemplate.from_template(GENERAL_PROMPT_TEMPLATE)
        general_chain = general_prompt | llm | StrOutputParser()

        routing_prompt = PromptTemplate.from_template(ROUTING_PROMPT_TEMPLATE)
        routing_chain = routing_prompt | llm | JsonOutputParser()

        logging.info("âœ¨ Ø§ÙƒØªÙ…Ù„Øª ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ù†Ø¬Ø§Ø­! âœ¨")
    except Exception as e:
        logging.critical(f"âŒ ÙØ´Ù„ Ø­Ø§Ø³Ù… Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©: {e}", exc_info=True)
        raise

# -----------------------------------------------------------------------------
# í—¬ Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# -----------------------------------------------------------------------------
def format_docs_with_source(docs: List[Document]) -> str:
    """ØªÙ†Ø³Ù‚ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© ÙˆØªØ¶ÙŠÙ Ø§Ù„Ù…ØµØ§Ø¯Ø±."""
    if not docs:
        return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ù…ØªÙˆÙØ±."
    sources = {doc.metadata.get("source", "Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ") for doc in docs}
    formatted_docs = "\n\n---\n\n".join(doc.page_content for doc in docs)
    return f"Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±: {', '.join(sources)}\n\n{formatted_docs}"

def perform_hybrid_retrieval_and_rerank(question: str, tenant_id: str, k: int) -> List[Document]:
    """ÙŠÙ†ÙØ° Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù‡Ø¬ÙŠÙ† Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨."""
    faiss_retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 15, "filter": {"tenant_id": tenant_id}})
    faiss_docs = faiss_retriever.invoke(question)
    
    tenant_docs_indices = [i for i, doc in enumerate(all_docs_for_bm25) if doc.metadata.get("tenant_id") == tenant_id]
    bm25_docs = []
    if tenant_docs_indices:
        tenant_corpus = [all_docs_for_bm25[i].page_content.split(" ") for i in tenant_docs_indices]
        bm25_for_tenant = BM25Okapi(tenant_corpus)
        tokenized_query = question.split(" ")
        doc_scores = bm25_for_tenant.get_scores(tokenized_query)
        top_n_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:15]
        bm25_docs = [all_docs_for_bm25[tenant_docs_indices[i]] for i in top_n_indices]
    
    combined_docs_list = list({doc.page_content: doc for doc in faiss_docs + bm25_docs}.values())
    if not combined_docs_list:
        return []

    # model_input_pairs = [[question, doc.page_content] for doc in combined_docs_list]
    # scores = cross_encoder.predict(model_input_pairs)
    # docs_with_scores = sorted(zip(combined_docs_list, scores), key=lambda x: x[1], reverse=True)
    
    # return [doc for doc, score in docs_with_scores[:k]]

# -----------------------------------------------------------------------------
# ğŸ§  Ø¨Ø« Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø©)
# -----------------------------------------------------------------------------
async def get_answer_stream(question: str, tenant_id: str, k_results: int = 4) -> AsyncGenerator[str, None]:
    if not routing_chain:
        raise RuntimeError("âš ï¸ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ØºÙŠØ± Ù…ÙÙ‡ÙŠØ£. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ initialize_agent() Ø£ÙˆÙ„Ø§Ù‹.")
    
    logging.info(f"ğŸ“© Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø³Ø¤Ø§Ù„ Ù…Ù† '{tenant_id}': {question}")
    try:
        # 1. Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡
        perf_logger.start("routing")
        route_decision = await routing_chain.ainvoke({"question": question})
        category = route_decision.get("category", "technical")
        perf_logger.end("routing", tenant_id, question, extra_info={"decision": category})
        logging.info(f"ğŸ§  Ù‚Ø±Ø§Ø± Ø§Ù„ØªÙˆØ¬ÙŠÙ‡: '{category}'")

        # 2. ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø³Ø§Ø±
        if category == "technical":
            logging.info("ğŸš€ ØªÙ†ÙÙŠØ° Ù…Ø³Ø§Ø± Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ (RAG)...")
            perf_logger.start("retrieval_rerank")
            final_docs = perform_hybrid_retrieval_and_rerank(question, tenant_id, k_results)
            perf_logger.end("retrieval_rerank", tenant_id, question, extra_info={"final_doc_count": len(final_docs)})
            
            # Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©
            entity_name = "Ø§Ù„Ø®Ø¯Ù…Ø©" # Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ
            if final_docs and "entity_name" in final_docs[0].metadata:
                entity_name = final_docs[0].metadata["entity_name"]
            logging.info(f"ğŸ¢ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø©: '{entity_name}'")
            
            async for chunk in full_rag_chain.astream({"question": question, "docs": final_docs, "tenant_name": entity_name}):
                yield chunk
        else: # general
            logging.info("ğŸ’¬ ØªÙ†ÙÙŠØ° Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ù…Ø©...")
            
            # Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø¹Ø¨Ø± Ø¨Ø­Ø« Ø®ÙÙŠÙ Ø¬Ø¯Ø§Ù‹
            temp_docs = vector_store.similarity_search("", filter={"tenant_id": tenant_id}, k=1)
            entity_name = "Ø§Ù„Ø®Ø¯Ù…Ø©" # Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ
            if temp_docs and "entity_name" in temp_docs[0].metadata:
                entity_name = temp_docs[0].metadata["entity_name"]
            logging.info(f"ğŸ¢ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø©: '{entity_name}'")

            async for chunk in general_chain.astream({"question": question, "tenant_name": entity_name}):
                yield chunk
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¨Ø« Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {e}", exc_info=True)
        yield "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ."
        perf_logger.end("error", tenant_id, question, extra_info={"error": str(e)})

